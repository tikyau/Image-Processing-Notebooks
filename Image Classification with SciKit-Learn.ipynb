{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with SciKit-Learn\n",
    "\n",
    "In this notebook, we'll explore some basic principles for building a classifier for images. Our classifier will be pretty simple, and will differentiate between circles, triangles, and squares.\n",
    "\n",
    "First let's create some sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate an image of random size and color\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = randint(10,200)\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else:\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# function to create a dataset of images\n",
    "def generate_image_data (shapes, size = (128,128), cases = 1000):\n",
    "    from skimage import exposure\n",
    "    \n",
    "    images = []\n",
    "    imagecodes = []\n",
    "    \n",
    "    i = 0\n",
    "    while(i < cases / len(shapes)):\n",
    "        for shape in shapes:        \n",
    "            # Append a new image to collection\n",
    "            images.append(create_image(size, shape))\n",
    "            \n",
    "            # append numeric code for label\n",
    "            imagecodes.append(shapes.index(shape))\n",
    "        i = i + 1\n",
    "    \n",
    "    return images, imagecodes\n",
    "\n",
    "\n",
    "# Now we're ready to generate some images\n",
    "# Our classes will be circles, triangles, and squares\n",
    "classnames = ['circle', 'triangle', 'square']\n",
    "\n",
    "# All images will be 128x128 pixels\n",
    "img_size = (128,128)\n",
    "\n",
    "# Generate 99 random images.\n",
    "images, imagecodes = generate_image_data(classnames, img_size, 99)\n",
    "\n",
    "# Create and display the first three images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(3):\n",
    "    ax = fig.add_subplot(1, 3, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(classnames[imagecodes[i]])\n",
    "    ax.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the images\n",
    "\n",
    "Generally, you'll need to clean up image data before training a model. You do this primarily to make the images you'll be training the model with consistent in terms of pixel intensity, contrast, size etc.\n",
    "\n",
    "In this case, we'll do some basic pre-processing by equalizing the pixel intensity of our images. In reality, you'd also need to resize them images to be a consistent size, apply filters to remove noise, and so on. What we want to end up with is a numpy array that represents the flattened, processed images\n",
    "\n",
    "*Note: You can ignore the warning produced by the following cell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_array):\n",
    "    from PIL import Image, ImageOps\n",
    "    \n",
    "    # Pre-process all of the images to make them consistent\n",
    "    images = []\n",
    "    for img in image_array:\n",
    "        # Equalize the pixel intensity to ensure consistent contrast\n",
    "        img = ImageOps.equalize(Image.fromarray(img))\n",
    "        # flatten the images\n",
    "        images.append(np.array(img).ravel())\n",
    "        \n",
    "        # (our images are all the same size - otherwise you should resize them!)\n",
    "        \n",
    "    return images\n",
    "\n",
    "# The pre-processed images are our features, the imagecodes are the labels\n",
    "import numpy as np\n",
    "features = np.array(preprocess_images(images))\n",
    "labels = np.array(imagecodes)\n",
    "print(labels.size, 'cases ready for training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "Now that the image data is prepared, we can split it into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.30)\n",
    "\n",
    "print('Training records:',Y_train.size)\n",
    "print('Test records:',Y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classification model\n",
    "\n",
    "Now we'll use the prepared image data to train a model.\n",
    "\n",
    "*(This may take a few minutes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set regularization rate\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model on the training set\n",
    "clf = LogisticRegression(C=1/reg, solver='lbfgs', multi_class='multinomial').fit(X_train, Y_train)\n",
    "print (clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "With our model trained, we'll use it to predict labels for the test data and evaluate its accuracy using the known labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model with new data\n",
    "Now we can use the model to classify new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((128,128), classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Modify the image data to match the format of the training features\n",
    "imgfeatures = np.array(ImageOps.equalize(Image.fromarray(img))).ravel().reshape(1, -1)\n",
    "\n",
    "pred = clf.predict(imgfeatures)\n",
    "print('The image is a', classnames[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "Take a look at the Image Classification tutorial in the SciKit-Learn documentation at http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
