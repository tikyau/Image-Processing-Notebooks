{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Convolutional Neural Network\n",
    "\n",
    "\"Deep Learning\" is a general term that usually refers to the use of neural networks with multiple layers that synthesize the way the human brain learns and makes decisions.\n",
    "\n",
    "## Some (Very) Basic Neural Network Theory\n",
    "\n",
    "Your brain works by connecting networks of neurons, each of which receives electrochemical stimuli from multiple inputs, which cause the neuron to fire under certain conditions. When a neuron fires, it creates an electrochemical charge that is passed as an input to one or more other neurons, creating a complex *feed-forward* network made up of layers of neurons that pass the signal on. An artificial neural network uses the same principles but the inputs are numeric values with associated *weights* that reflect their relative importance. The neuron take these input values and weights and applies them to an *activation function* that determines whether the artificial neuron should pass an output onto the next layer:\n",
    "\n",
    "$$ \\rightrightarrows\\oint\\rightarrow $$\n",
    "\n",
    "As the human brain learns from experience, the inputs to the neurons are strenghtened or weakened depending on their importance to the decisions that the brain needs to make in response to stimuli. Similarly, you train an artificial neural network using a supervised leaning technique in which a *loss function* is used to evaluate how well the multi-layered model detects known labels. You can then find the derivative of the loss function to determine whether the level of error (loss) is reduced by increasing or decreasing the weights associated with the inputs, and then apply *backpropagation* to adjust the weights and improve the model iteratively over multiple training *epochs*. The result of this training is a deep learning model that consists of:\n",
    "* An *input* layer to which the initial input variables are passed.\n",
    "* One or more *hidden* layers in which the weights optimized by training determine the signal that is fed forward through the network.\n",
    "* An *output* layer that presents the results.\n",
    "\n",
    "## Convolutional Neural Networks (CNNs)\n",
    "Convolutional Neural Networks, or *CNNs*, are a particular type of artificial neural network that works well with matrix inputs, such as images (which are fundamentally just matrices of pixel intensity values). There are various kinds of layer in a CNN, but a common architecture is to build a sequence of *convolutional* layers that find patterns in indvidual areas of the input matrix and *pooling* layers that aggregate these patterns. Additionally, some layers may *drop* data (which helps avoid *overfitting* the model to the training data), and finally some layers will *flatten* the matrix data and a *dense*, or *fully connected* layer will perform classification and reshape the predictions to conform with the expected output format.\n",
    "\n",
    "### Convolutional Layers\n",
    "Convolutional layers apply filters to a subregion of the input image, and *convolve* the filter across the image to extract features (such as edges, corners, etc.). For example, suppose the following matrix represents the pixels in a 6x6 image:\n",
    "\n",
    "$$\\begin{bmatrix}255 & 255 & 255 & 255 & 255 & 255\\\\255 & 255 & 0 & 0 & 255 & 255\\\\255 & 0 & 0 & 0 & 0 & 255\\\\255 & 0 & 0 & 0 & 0 & 255\\\\255 & 255 & 0 & 0 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n",
    "\n",
    "And let's suppose that a filter matrix is defined like this:\n",
    "\n",
    "$$\\begin{bmatrix}0 & 1 & 0\\\\0 & 1 & 0\\\\0 & 1 & 0\\end{bmatrix}$$\n",
    "\n",
    "The convolution layer applies the filter to the image matrix one \"patch\" at a time; so the first operation would apply to the <span style=\"color:red\">red</span> elements below:\n",
    "\n",
    "$$\\begin{bmatrix}\\color{red}{255} & \\color{red}{255} & \\color{red}{255} & 255 & 255 & 255\\\\\\color{red}{255} & \\color{red}{255} & \\color{red}{0} & 0 & 255 & 255\\\\\\color{red}{255} & \\color{red}{0} & \\color{red}{0} & 0 & 0 & 255\\\\255 & 0 & 0 & 0 & 0 & 255\\\\255 & 255 & 0 & 0 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n",
    "\n",
    "To apply the filter, we multiply the patch area by the filter elementwise, and add the results:\n",
    "\n",
    "$$\\begin{bmatrix}255 & 255 & 255\\\\255 & 255 & 0\\\\255 & 0 & 0\\end{bmatrix} \\times \\begin{bmatrix}0 & 1 & 0\\\\0 & 1 & 0\\\\0 & 1 & 0\\end{bmatrix}= \\begin{bmatrix}(255 \\times 0) + (255 \\times 1) + (255 \\times 0) & +\\\\ (255 \\times 0) + (255 \\times 1) + (0 \\times 0) & + \\\\ (255 \\times 0) + (0 \\times 1) + (0 \\times 0)\\end{bmatrix}  = 510$$\n",
    "\n",
    "This result is then used as the value for the first element of a feature map that is the size of the original image minus the outside edge elements:\n",
    "\n",
    "$$\\begin{bmatrix}\\color{red}{510} & ? & ? & ?\\\\? & ? & ? & ?\\\\? & ? & ? & ?\\\\? & ? & ? & ?\\end{bmatrix}$$\n",
    "\n",
    "Next we move the patch along one pixel and apply the filter to the new patch area:\n",
    "\n",
    "$$\\begin{bmatrix}255 & \\color{red}{255} & \\color{red}{255} & \\color{red}{255} & 255 & 255\\\\255 & \\color{red}{255} & \\color{red}{0} & \\color{red}{0} & 255 & 255\\\\255 & \\color{red}{0} & \\color{red}{0} & \\color{red}{0} & 0 & 255\\\\255 & 0 & 0 & 0 & 0 & 255\\\\255 & 255 & 0 & 0 & 255 & 255\\\\255 & 255 & 255 & 255 & 255 & 255\\end{bmatrix}$$\n",
    "\n",
    "$$\\begin{bmatrix}255 & 255 & 255\\\\255 & 0 & 0\\\\0 & 0 & 0\\end{bmatrix} \\times \\begin{bmatrix}0 & 1 & 0\\\\0 & 1 & 0\\\\0 & 1 & 0\\end{bmatrix}= \\begin{bmatrix}(255 \\times 0) + (255 \\times 1) + (255 \\times 0) & +\\\\ (255 \\times 0) + (0 \\times 1) + (0 \\times 0) & + \\\\ (0 \\times 0) + (0 \\times 1) + (0 \\times 0)\\end{bmatrix}  = 255 $$\n",
    "\n",
    "So can fill in that value on our feature map:\n",
    "$$\\begin{bmatrix}510 & \\color{red}{255} & ? & ?\\\\? & ? & ? & ?\\\\? & ? & ? & ?\\\\? & ? & ? & ?\\end{bmatrix}$$\n",
    "\n",
    "Then we just repeat the process, moving the patch across the entire image matrix until we have a completed feature map like this:\n",
    "\n",
    "$$\\begin{bmatrix}510 & 255 & 255 & 510\\\\255 & 0 & 0 & 255\\\\255 & 0 & 0 & 255\\\\510 & 255 & 255 & 510\\end{bmatrix}$$\n",
    "\n",
    "### Pooling Layers\n",
    "After using one or more convolution layers to create a filter map, you can use a pooling layer to  reduce the number of dimensions in the matrix. A common technique is to use *MaxPooling*, in which a patch is applied to the matrix and the maximum value within the mask is retained while the others are discarded.\n",
    "\n",
    "For example, we could apply a 2x2 patch to our feature map to extract the largest value in each 2x2 subarea:\n",
    "\n",
    "$$\\begin{bmatrix}\\color{blue}{510} & \\color{blue}{255} & \\color{green}{255} & \\color{green}{510}\\\\\\color{blue}{255} & \\color{blue}{0} & \\color{green}{0} & \\color{green}{255}\\\\\\color{magenta}{255} & \\color{magenta}{0} & \\color{orange}{0} & \\color{orange}{255}\\\\\\color{magenta}{510} & \\color{magenta}{255} & \\color{orange}{255} & \\color{orange}{510}\\end{bmatrix} \\Longrightarrow \\begin{bmatrix}\\color{blue}{510} & \\color{green}{510}\\\\\\color{magenta}{510} & \\color{orange}{510}\\end{bmatrix}$$\n",
    "\n",
    "### Dropout Layers\n",
    "In any machine learning training process, there is a danger of *overfitting* the model to the training data. In other words, you might end with a model that works extremely well with the data on which it was trained, but can't generalize effectively to classify new images. One way in which you can reduce the risk of overfitting is to randomly drop some features.\n",
    "\n",
    "### Dense (Fully-Connected) Layers\n",
    "After the previous layers have created feature maps, a final *fully-connected* layer is used to generate class predictions - you can think of the fully-connected layer as being the endpoint of the classifier what determines which combination of features found in the previous layers \"adds up\" to a particular class.\n",
    "\n",
    "## Building a CNN\n",
    "There are several commonly used frameworks for creating CNNs, including The *Microsoft Cognitive Toolkit (CNTK)*, *Tenserflow*, and *Keras* (which is a high-level API that can use Tenserflow or CNTK as a back end). \n",
    "\n",
    "### A Simple Example\n",
    "In this notebook, we'll build a simple example CNN using Keras with a CNTK back end. The example is a classification model that can classify an image as a circle, a triangle, or a square.\n",
    "\n",
    "First, we'll create some functions that can be used to generate the images for our classification model. Run the cell below to create these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate an image of random size and color\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = randint(10,200)\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# function to create a dataset of images\n",
    "def generate_image_data (shapes, size = (128,128), cases = 1000):\n",
    "    images = []\n",
    "    imagecodes = []\n",
    "    \n",
    "    i = 0\n",
    "    while(i < cases / len(shapes)):\n",
    "        for shape in shapes:\n",
    "            images.append(create_image(size, shape))\n",
    "            imagecodes.append(shapes.index(shape))\n",
    "        i = i + 1\n",
    "    \n",
    "    return images, imagecodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a set of images with which to train and validate a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Our classes will be circles, triagnles. and squares\n",
    "classnames = ['circle', 'triangle', 'square']\n",
    "\n",
    "# All images will be 128x128 pixels\n",
    "img_size = (128,128)\n",
    "\n",
    "# Generate 1500 random images.\n",
    "images, imagecodes = generate_image_data(classnames, img_size, 1500)\n",
    "\n",
    "print(len(images), 'images generated. Here are the first three:')\n",
    "\n",
    "# Display the first three images\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(3):\n",
    "    ax = fig.add_subplot(1, 3, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(classnames[imagecodes[i]])\n",
    "    ax.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Frameworks\n",
    "Now that we have our data, we're ready to build a CNN. The first step is to install and configure the frameworks we want to use.\n",
    "\n",
    "First, we'll install a version of CNTK that is compatible with Keras on Python 3.5.\n",
    "\n",
    "> **Note**: The following code installs the correct version of CNTK on Azure Notebooks. To install CNTK on your own system, consult the CNTK documentation at https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-CNTK-on-your-machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Upgrade CNTK to 2.3.1 for Python 3.5\n",
    "!pip install --upgrade --no-deps https://cntk.ai/PythonWheel/CPU-Only/cntk-2.3.1-cp35-cp35m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Keras\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll configure Keras to use CNTK as a back end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Keras backend to CNTK\n",
    "from keras import backend as K\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"cntk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "Before we can train the model, we need to prepare the data. When working with CNTK, Keras expects the numeric values to be 32-bit floating point numbers, so we'll cast our features and labels to that type. We'll also divide the feature values by 255 to normalize the values, and we'll convert the numeric labels into categories that match the number of classes in our data (in this case, three - *circle*, *triangle*, and *square*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_array):\n",
    "    from PIL import Image, ImageOps\n",
    "    \n",
    "    # Pre-process all of the images to make them consistent\n",
    "    images = []\n",
    "    for img in image_array:\n",
    "        # Equalize the pixel intensity to ensure consistent contrast\n",
    "        img = ImageOps.equalize(Image.fromarray(img))\n",
    "        # flatten the images\n",
    "        images.append(np.array(img))\n",
    "        \n",
    "        # (our images are all the same size - otherwise you should resize them!)\n",
    "        \n",
    "    return images\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# The images are our features, the imagecodes are the labels\n",
    "features = np.array(preprocess_images(images))\n",
    "labels = np.array(imagecodes)\n",
    "\n",
    "#Format features\n",
    "features = features.astype('float32')\n",
    "features /= 255\n",
    "\n",
    "# Format labels\n",
    "labels = to_categorical(labels, len(classnames))\n",
    "labels = labels.astype('float32')\n",
    "\n",
    "# Show the shape of the features array (num_images, width, height, channels)\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the CNN\n",
    "Now we're ready to train our model. This involves defining the layers for our CNN, and compiling them for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a CNN classifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# Define the model as a sequence of layers\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer accepts an image and applies a convolution that uses 32 6x6 filters and a rectified linear unit activation function\n",
    "model.add(Conv2D(32, (6, 6), input_shape=(features.shape[1], features.shape[2], features.shape[3]), activation='relu'))\n",
    "\n",
    "# Next we;ll add a max pooling layer with a 2x2 patch\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# A dropout layer randomly drops some nodes to reduce inter-dependencies (which can cause over-fitting)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# We can add as many layers as we think necessary - here we'll add another convolution, max pooling, and dropout layer\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# And another set\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Now we'll flatten the feature maps and generate an output layer with a predicted probability for each class\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(classnames), activation='softmax'))\n",
    "\n",
    "# With the layers defined, we can ow compile the model for categorical (multi-class) classification\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "With the layers of the CNN defined, we're ready to train the model using our image data. In the example below, we use 3 iterations (*epochs*) to train the model in 50-image batches, holding back 30% of the data for validation. After each epoch, the loss function detects the error in the model and adjusts the weights (which were randomly generated for the first iteration) to try to improve accuracy. \n",
    "\n",
    "> **Note**: We're only using 3 epochs to reduce the training time for this simple example. A real-world CNN is usually trained over more epochs than this (50 is a common starting point). CNN model training is processor-intensive, so it's recommended to perform this on a system that can leverage GPUs as well as CPUs (such as the Data Science Virtual Machine in Azure) to reduce training time. This will take a while to complete in Azure Notebooks (in which GPUs are not available) - status will be displayed as the training progresses. Feel free to go get some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model over 3 epochs using 50-image batches and holding back the last 30% of the data for validation\n",
    "model.fit(features, labels, epochs=3, batch_size=50, validation_split=0.3)\n",
    "\n",
    "# Note: The validation_split parameter holds back the last X% (in this case 30%) of the training data WITHOUT shuffling the data.\n",
    "# Our data is ordered such that instances the three classes are distributed evenly, so this is fine.\n",
    "# If the data is ordered such that the the last X% doesn't contain a mix of all classes, you should either:\n",
    "#   - Shuffle the data before training (ensuring features still match corresponding labels.)\n",
    "#   - Randomly split the data first and use the validation_data parameter instead of validation_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Trained Model\n",
    "Now that we've trained the model, we can use it to predict the class of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((128,128), classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Modify the image data to match the format of the training features\n",
    "img = np.array(ImageOps.equalize(Image.fromarray(img)))\n",
    "imgfeatures = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "imgfeatures = imgfeatures.astype('float32')\n",
    "imgfeatures /= 255\n",
    "\n",
    "# Use the classifier to predict the class\n",
    "predicted_class = model.predict(imgfeatures)\n",
    "# Print the predicted probabilities for each class\n",
    "print(predicted_class)\n",
    "# Find the class with the highest predicted probability\n",
    "i = np.where(predicted_class == predicted_class.max())\n",
    "print (classnames[int(i[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning More\n",
    "* [CNTK Documentation](https://docs.microsoft.com/en-us/cognitive-toolkit/)\n",
    "* [Keras Documentation](https://keras.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
